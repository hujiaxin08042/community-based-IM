[
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "statistics",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "statistics",
        "description": "statistics",
        "detail": "statistics",
        "documentation": {}
    },
    {
        "label": "ndlib.models.epidemics",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ndlib.models.epidemics",
        "description": "ndlib.models.epidemics",
        "detail": "ndlib.models.epidemics",
        "documentation": {}
    },
    {
        "label": "ndlib.models.ModelConfig",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ndlib.models.ModelConfig",
        "description": "ndlib.models.ModelConfig",
        "detail": "ndlib.models.ModelConfig",
        "documentation": {}
    },
    {
        "label": "Munkres",
        "importPath": "munkres",
        "description": "munkres",
        "isExtraImport": true,
        "detail": "munkres",
        "documentation": {}
    },
    {
        "label": "print_matrix",
        "importPath": "munkres",
        "description": "munkres",
        "isExtraImport": true,
        "detail": "munkres",
        "documentation": {}
    },
    {
        "label": "Munkres",
        "importPath": "munkres",
        "description": "munkres",
        "isExtraImport": true,
        "detail": "munkres",
        "documentation": {}
    },
    {
        "label": "print_matrix",
        "importPath": "munkres",
        "description": "munkres",
        "isExtraImport": true,
        "detail": "munkres",
        "documentation": {}
    },
    {
        "label": "normalized_mutual_info_score",
        "importPath": "sklearn.metrics.cluster",
        "description": "sklearn.metrics.cluster",
        "isExtraImport": true,
        "detail": "sklearn.metrics.cluster",
        "documentation": {}
    },
    {
        "label": "normalized_mutual_info_score",
        "importPath": "sklearn.metrics.cluster",
        "description": "sklearn.metrics.cluster",
        "isExtraImport": true,
        "detail": "sklearn.metrics.cluster",
        "documentation": {}
    },
    {
        "label": "normalized_mutual_info_score",
        "importPath": "sklearn.metrics.cluster",
        "description": "sklearn.metrics.cluster",
        "isExtraImport": true,
        "detail": "sklearn.metrics.cluster",
        "documentation": {}
    },
    {
        "label": "normalized_mutual_info_score",
        "importPath": "sklearn.metrics.cluster",
        "description": "sklearn.metrics.cluster",
        "isExtraImport": true,
        "detail": "sklearn.metrics.cluster",
        "documentation": {}
    },
    {
        "label": "normalized_mutual_info_score",
        "importPath": "sklearn.metrics.cluster",
        "description": "sklearn.metrics.cluster",
        "isExtraImport": true,
        "detail": "sklearn.metrics.cluster",
        "documentation": {}
    },
    {
        "label": "adjusted_rand_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "pairwise_distances",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "adjusted_rand_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "adjusted_rand_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "adjusted_rand_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "adjusted_rand_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "linear_sum_assignment",
        "importPath": "scipy.optimize",
        "description": "scipy.optimize",
        "isExtraImport": true,
        "detail": "scipy.optimize",
        "documentation": {}
    },
    {
        "label": "linear_sum_assignment",
        "importPath": "scipy.optimize",
        "description": "scipy.optimize",
        "isExtraImport": true,
        "detail": "scipy.optimize",
        "documentation": {}
    },
    {
        "label": "metrics",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "metrics",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "h5py",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "h5py",
        "description": "h5py",
        "detail": "h5py",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "Linear",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "Linear",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "Linear",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "Linear",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "Parameter",
        "importPath": "torch.nn.parameter",
        "description": "torch.nn.parameter",
        "isExtraImport": true,
        "detail": "torch.nn.parameter",
        "documentation": {}
    },
    {
        "label": "Parameter",
        "importPath": "torch.nn.parameter",
        "description": "torch.nn.parameter",
        "isExtraImport": true,
        "detail": "torch.nn.parameter",
        "documentation": {}
    },
    {
        "label": "Parameter",
        "importPath": "torch.nn.parameter",
        "description": "torch.nn.parameter",
        "isExtraImport": true,
        "detail": "torch.nn.parameter",
        "documentation": {}
    },
    {
        "label": "Parameter",
        "importPath": "torch.nn.parameter",
        "description": "torch.nn.parameter",
        "isExtraImport": true,
        "detail": "torch.nn.parameter",
        "documentation": {}
    },
    {
        "label": "Parameter",
        "importPath": "torch.nn.parameter",
        "description": "torch.nn.parameter",
        "isExtraImport": true,
        "detail": "torch.nn.parameter",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Adam",
        "importPath": "torch.optim",
        "description": "torch.optim",
        "isExtraImport": true,
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "SGD",
        "importPath": "torch.optim",
        "description": "torch.optim",
        "isExtraImport": true,
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "Adam",
        "importPath": "torch.optim",
        "description": "torch.optim",
        "isExtraImport": true,
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "Adam",
        "importPath": "torch.optim",
        "description": "torch.optim",
        "isExtraImport": true,
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "Adam",
        "importPath": "torch.optim",
        "description": "torch.optim",
        "isExtraImport": true,
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "KMeans",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "KMeans",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "KMeans",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "KMeans",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "eva",
        "importPath": "evaluation",
        "description": "evaluation",
        "isExtraImport": true,
        "detail": "evaluation",
        "documentation": {}
    },
    {
        "label": "eva",
        "importPath": "evaluation",
        "description": "evaluation",
        "isExtraImport": true,
        "detail": "evaluation",
        "documentation": {}
    },
    {
        "label": "eva",
        "importPath": "evaluation",
        "description": "evaluation",
        "isExtraImport": true,
        "detail": "evaluation",
        "documentation": {}
    },
    {
        "label": "eva",
        "importPath": "evaluation",
        "description": "evaluation",
        "isExtraImport": true,
        "detail": "evaluation",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "Module",
        "importPath": "torch.nn.modules.module",
        "description": "torch.nn.modules.module",
        "isExtraImport": true,
        "detail": "torch.nn.modules.module",
        "documentation": {}
    },
    {
        "label": "multiprocessing",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "Process",
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "isExtraImport": true,
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "Queue",
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "isExtraImport": true,
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "Lock",
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "isExtraImport": true,
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "Process",
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "isExtraImport": true,
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "Queue",
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "isExtraImport": true,
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "Lock",
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "isExtraImport": true,
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "networkx",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "networkx",
        "description": "networkx",
        "detail": "networkx",
        "documentation": {}
    },
    {
        "label": "pensize",
        "importPath": "turtle",
        "description": "turtle",
        "isExtraImport": true,
        "detail": "turtle",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "cosine_similarity",
        "importPath": "sklearn.metrics.pairwise",
        "description": "sklearn.metrics.pairwise",
        "isExtraImport": true,
        "detail": "sklearn.metrics.pairwise",
        "documentation": {}
    },
    {
        "label": "normalize",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "IC",
        "importPath": "IC",
        "description": "IC",
        "isExtraImport": true,
        "detail": "IC",
        "documentation": {}
    },
    {
        "label": "IC",
        "importPath": "IC",
        "description": "IC",
        "isExtraImport": true,
        "detail": "IC",
        "documentation": {}
    },
    {
        "label": "IC",
        "importPath": "IC",
        "description": "IC",
        "isExtraImport": true,
        "detail": "IC",
        "documentation": {}
    },
    {
        "label": "IC",
        "importPath": "IC",
        "description": "IC",
        "isExtraImport": true,
        "detail": "IC",
        "documentation": {}
    },
    {
        "label": "IC",
        "importPath": "IC",
        "description": "IC",
        "isExtraImport": true,
        "detail": "IC",
        "documentation": {}
    },
    {
        "label": "IC",
        "importPath": "IC",
        "description": "IC",
        "isExtraImport": true,
        "detail": "IC",
        "documentation": {}
    },
    {
        "label": "get_graph",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "get_graph",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "load_data",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "load_graph",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "load_data",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "load_graph",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "load_data",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "load_graph",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "igraph",
        "description": "igraph",
        "isExtraImport": true,
        "detail": "igraph",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "igraph",
        "description": "igraph",
        "isExtraImport": true,
        "detail": "igraph",
        "documentation": {}
    },
    {
        "label": "celf",
        "importPath": "celf_networkx",
        "description": "celf_networkx",
        "isExtraImport": true,
        "detail": "celf_networkx",
        "documentation": {}
    },
    {
        "label": "greedy",
        "importPath": "greedy_networkx",
        "description": "greedy_networkx",
        "isExtraImport": true,
        "detail": "greedy_networkx",
        "documentation": {}
    },
    {
        "label": "greedy",
        "importPath": "greedy_networkx",
        "description": "greedy_networkx",
        "isExtraImport": true,
        "detail": "greedy_networkx",
        "documentation": {}
    },
    {
        "label": "celf",
        "importPath": "celf_p",
        "description": "celf_p",
        "isExtraImport": true,
        "detail": "celf_p",
        "documentation": {}
    },
    {
        "label": "get_graph",
        "importPath": "community",
        "description": "community",
        "isExtraImport": true,
        "detail": "community",
        "documentation": {}
    },
    {
        "label": "celf",
        "importPath": "celf",
        "description": "celf",
        "isExtraImport": true,
        "detail": "celf",
        "documentation": {}
    },
    {
        "label": "celf",
        "importPath": "celf",
        "description": "celf",
        "isExtraImport": true,
        "detail": "celf",
        "documentation": {}
    },
    {
        "label": "celf",
        "importPath": "celf",
        "description": "celf",
        "isExtraImport": true,
        "detail": "celf",
        "documentation": {}
    },
    {
        "label": "celf",
        "importPath": "celf",
        "description": "celf",
        "isExtraImport": true,
        "detail": "celf",
        "documentation": {}
    },
    {
        "label": "print_function",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "division",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "print_function",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "division",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "print_function",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "division",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "GNNLayer",
        "importPath": "GNN",
        "description": "GNN",
        "isExtraImport": true,
        "detail": "GNN",
        "documentation": {}
    },
    {
        "label": "GNNLayer",
        "importPath": "GNN",
        "description": "GNN",
        "isExtraImport": true,
        "detail": "GNN",
        "documentation": {}
    },
    {
        "label": "GNNLayer",
        "importPath": "GNN",
        "description": "GNN",
        "isExtraImport": true,
        "detail": "GNN",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "mpCommCelf",
        "importPath": "mpTest",
        "description": "mpTest",
        "isExtraImport": true,
        "detail": "mpTest",
        "documentation": {}
    },
    {
        "label": "mpCommAI",
        "importPath": "mpTest",
        "description": "mpTest",
        "isExtraImport": true,
        "detail": "mpTest",
        "documentation": {}
    },
    {
        "label": "scipy.sparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy.sparse",
        "description": "scipy.sparse",
        "detail": "scipy.sparse",
        "documentation": {}
    },
    {
        "label": "rand",
        "kind": 2,
        "importPath": "NIB.baseline_random",
        "description": "NIB.baseline_random",
        "peekOfCode": "def rand(g, cost, population, infected, infected_no, config):\n    for percent in range(5, 55, 5):\n        k = int(population * percent / 100)\n        result = []\n        times = []\n        # Repeat 10 times\n        for t in range(10):\n            start = time.time()\n            randomlist = [None] * 5000\n            for i in range(5000):",
        "detail": "NIB.baseline_random",
        "documentation": {}
    },
    {
        "label": "cluster_acc",
        "kind": 2,
        "importPath": "data.evaluation",
        "description": "data.evaluation",
        "peekOfCode": "def cluster_acc(y_true, y_pred):\n    y_true = y_true - np.min(y_true)\n    l1 = list(set(y_true))\n    numclass1 = len(l1)\n    l2 = list(set(y_pred))\n    numclass2 = len(l2)\n    ind = 0\n    if numclass1 != numclass2:\n        for i in l1:\n            if i in l2:",
        "detail": "data.evaluation",
        "documentation": {}
    },
    {
        "label": "eva",
        "kind": 2,
        "importPath": "data.evaluation",
        "description": "data.evaluation",
        "peekOfCode": "def eva(y_true, y_pred, epoch=0):\n    acc, f1 = cluster_acc(y_true, y_pred)\n    nmi = nmi_score(y_true, y_pred, average_method='arithmetic')\n    ari = ari_score(y_true, y_pred)\n    print(epoch, ':acc {:.4f}'.format(acc), ', nmi {:.4f}'.format(nmi), ', ari {:.4f}'.format(ari),\n            ', f1 {:.4f}'.format(f1))",
        "detail": "data.evaluation",
        "documentation": {}
    },
    {
        "label": "AE",
        "kind": 6,
        "importPath": "data.pretrain",
        "description": "data.pretrain",
        "peekOfCode": "class AE(nn.Module):\n    def __init__(self, n_enc_1, n_enc_2, n_enc_3, n_dec_1, n_dec_2, n_dec_3,\n                 n_input, n_z):\n        super(AE, self).__init__()\n        self.enc_1 = Linear(n_input, n_enc_1)\n        self.enc_2 = Linear(n_enc_1, n_enc_2)\n        self.enc_3 = Linear(n_enc_2, n_enc_3)\n        self.z_layer = Linear(n_enc_3, n_z)\n        self.dec_1 = Linear(n_z, n_dec_1)\n        self.dec_2 = Linear(n_dec_1, n_dec_2)",
        "detail": "data.pretrain",
        "documentation": {}
    },
    {
        "label": "LoadDataset",
        "kind": 6,
        "importPath": "data.pretrain",
        "description": "data.pretrain",
        "peekOfCode": "class LoadDataset(Dataset):\n    def __init__(self, data):\n        self.x = data\n    def __len__(self):\n        return self.x.shape[0]\n    def __getitem__(self, idx):\n        return torch.from_numpy(np.array(self.x[idx])).float(), \\\n               torch.from_numpy(np.array(idx))\ndef adjust_learning_rate(optimizer, epoch):\n    lr = 0.001 * (0.1 ** (epoch // 20))",
        "detail": "data.pretrain",
        "documentation": {}
    },
    {
        "label": "adjust_learning_rate",
        "kind": 2,
        "importPath": "data.pretrain",
        "description": "data.pretrain",
        "peekOfCode": "def adjust_learning_rate(optimizer, epoch):\n    lr = 0.001 * (0.1 ** (epoch // 20))\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\ndef pretrain_ae(model, dataset, y):\n    train_loader = DataLoader(dataset, batch_size=256, shuffle=True)\n    print(model)\n    optimizer = Adam(model.parameters(), lr=1e-3)\n    for epoch in range(30):\n        # adjust_learning_rate(optimizer, epoch)",
        "detail": "data.pretrain",
        "documentation": {}
    },
    {
        "label": "pretrain_ae",
        "kind": 2,
        "importPath": "data.pretrain",
        "description": "data.pretrain",
        "peekOfCode": "def pretrain_ae(model, dataset, y):\n    train_loader = DataLoader(dataset, batch_size=256, shuffle=True)\n    print(model)\n    optimizer = Adam(model.parameters(), lr=1e-3)\n    for epoch in range(30):\n        # adjust_learning_rate(optimizer, epoch)\n        for batch_idx, (x, _) in enumerate(train_loader):\n            x = x.cuda()\n            x_bar, _ = model(x)\n            loss = F.mse_loss(x_bar, x)",
        "detail": "data.pretrain",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "data.pretrain",
        "description": "data.pretrain",
        "peekOfCode": "model = AE(\n        n_enc_1=500,\n        n_enc_2=500,\n        n_enc_3=2000,\n        n_dec_1=2000,\n        n_dec_2=500,\n        n_dec_3=500,\n        n_input=334,\n        n_z=10,).cuda()\nx = np.loadtxt('dblp.txt', dtype=float)",
        "detail": "data.pretrain",
        "documentation": {}
    },
    {
        "label": "x",
        "kind": 5,
        "importPath": "data.pretrain",
        "description": "data.pretrain",
        "peekOfCode": "x = np.loadtxt('dblp.txt', dtype=float)\ny = np.loadtxt('dblp_label.txt', dtype=int)\ndataset = LoadDataset(x)\npretrain_ae(model, dataset, y)",
        "detail": "data.pretrain",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": "data.pretrain",
        "description": "data.pretrain",
        "peekOfCode": "y = np.loadtxt('dblp_label.txt', dtype=int)\ndataset = LoadDataset(x)\npretrain_ae(model, dataset, y)",
        "detail": "data.pretrain",
        "documentation": {}
    },
    {
        "label": "dataset",
        "kind": 5,
        "importPath": "data.pretrain",
        "description": "data.pretrain",
        "peekOfCode": "dataset = LoadDataset(x)\npretrain_ae(model, dataset, y)",
        "detail": "data.pretrain",
        "documentation": {}
    },
    {
        "label": "GNNLayer",
        "kind": 6,
        "importPath": "GNN",
        "description": "GNN",
        "peekOfCode": "class GNNLayer(Module):\n    def __init__(self, in_features, out_features):\n        super(GNNLayer, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n        torch.nn.init.xavier_uniform_(self.weight)\n    def forward(self, features, adj, active=True):\n        support = torch.mm(features, self.weight)\n        output = torch.spmm(adj, support)",
        "detail": "GNN",
        "documentation": {}
    },
    {
        "label": "InfWorker",
        "kind": 6,
        "importPath": "IC",
        "description": "IC",
        "peekOfCode": "class InfWorker(mp.Process):\n    def __init__(self, outQ, count, inf_function):\n        super(InfWorker, self).__init__(target=self.start)\n        self.outQ = outQ\n        self.count = count\n        self.inf_function = inf_function\n        self.sum = 0\n    def run(self):\n        while self.count > 0:\n            res = self.inf_function()",
        "detail": "IC",
        "documentation": {}
    },
    {
        "label": "ICModel",
        "kind": 6,
        "importPath": "IC",
        "description": "IC",
        "peekOfCode": "class ICModel:\n    def __init__(self, threshold_method='random', graph=None, seeds=None, worker_num=8, simulate_times=10000, p=0.5) -> None:\n        self.tsm = threshold_method\n        self.graph = graph\n        self.worker_num = worker_num\n        self.simulate_times = simulate_times\n        self.seeds = seeds\n        self.p = p\n    def influence_func(self):\n        assert self.graph != None and self.seeds != None",
        "detail": "IC",
        "documentation": {}
    },
    {
        "label": "create_worker",
        "kind": 2,
        "importPath": "IC",
        "description": "IC",
        "peekOfCode": "def create_worker(worker, num, task_num, inf_function):\n    \"\"\"\n        create processes\n        :param num: process number\n        :param task_num: the number of tasks assigned to each worker\n    \"\"\"\n    for i in range(num):\n        worker.append(InfWorker(mp.Queue(), task_num, inf_function))\n        worker[i].start()\ndef finish_worker(worker):",
        "detail": "IC",
        "documentation": {}
    },
    {
        "label": "finish_worker",
        "kind": 2,
        "importPath": "IC",
        "description": "IC",
        "peekOfCode": "def finish_worker(worker):\n    \"\"\"\n    关闭所有子进程\n    :return:\n    \"\"\"\n    for w in worker:\n        w.terminate()\nclass ICModel:\n    def __init__(self, threshold_method='random', graph=None, seeds=None, worker_num=8, simulate_times=10000, p=0.5) -> None:\n        self.tsm = threshold_method",
        "detail": "IC",
        "documentation": {}
    },
    {
        "label": "IC",
        "kind": 2,
        "importPath": "IC",
        "description": "IC",
        "peekOfCode": "def IC(g, S, p=0.1, mc=10000, method='random'):\n    # graph: network 图\n    # S: 种子集\n    # p: 影响概率\n    # mc: 模拟次数\n    # method:\n    #   - random: 影响概率pp固定，阈值随机\n    #   - pp_random: 影响概率pp事先计算，阈值随机\n    model = ICModel(threshold_method=method, graph=g, seeds=S, worker_num=8, simulate_times=mc, p=p)\n    influence = model.calculate_influence()",
        "detail": "IC",
        "documentation": {}
    },
    {
        "label": "IC",
        "kind": 2,
        "importPath": "IC_test",
        "description": "IC_test",
        "peekOfCode": "def IC(g, S, mc=1000):\n    spread = []\n    for i in range(mc):\n        newActive = True\n        currentActiveNodes = S[:]\n        newActiveNodes = set()\n        activatedNodes = S[:]  \n        influenceSpread = len(S)\n        np.random.seed(i)\n        while (newActive):",
        "detail": "IC_test",
        "documentation": {}
    },
    {
        "label": "calcu_cosine",
        "kind": 2,
        "importPath": "calcu_cosine",
        "description": "calcu_cosine",
        "peekOfCode": "def calcu_cosine(vec1, vec2):\n    cos_sim = vec1.dot(vec2) / np.linalg.norm(vec1) * np.linalg.norm(vec2)\n    return cos_sim\nif __name__ == '__main__':\n    x = np.loadtxt('data/dblp_result_Z_class.txt')\n    f1 = open('graph/dblp_graph.txt', 'r', encoding='utf-8')\n    f2 = open('result/dblp/dblp_cosine.txt', 'w', encoding='utf-8')\n    # node = []\n    # for line in f1.readlines():\n    #     res = line.replace('[', '').replace(']', '').replace('\\n', '').replace(' ', '').split(' ')",
        "detail": "calcu_cosine",
        "documentation": {}
    },
    {
        "label": "construct_graph",
        "kind": 2,
        "importPath": "calcu_graph",
        "description": "calcu_graph",
        "peekOfCode": "def construct_graph(features, label, method='heat'):\n    fname = 'graph/reut10_graph.txt'\n    num = len(label)\n    dist = None\n    if method == 'heat':\n        dist = -0.5 * pair(features) ** 2\n        dist = np.exp(dist)\n    elif method == 'cos':\n        features[features > 0] = 1\n        dist = np.dot(features, features.T)",
        "detail": "calcu_graph",
        "documentation": {}
    },
    {
        "label": "topk",
        "kind": 5,
        "importPath": "calcu_graph",
        "description": "calcu_graph",
        "peekOfCode": "topk = 10\ndef construct_graph(features, label, method='heat'):\n    fname = 'graph/reut10_graph.txt'\n    num = len(label)\n    dist = None\n    if method == 'heat':\n        dist = -0.5 * pair(features) ** 2\n        dist = np.exp(dist)\n    elif method == 'cos':\n        features[features > 0] = 1",
        "detail": "calcu_graph",
        "documentation": {}
    },
    {
        "label": "f",
        "kind": 5,
        "importPath": "calcu_graph",
        "description": "calcu_graph",
        "peekOfCode": "f = h5py.File('data/usps.h5', 'r')\ntrain = f.get('train')\ntest = f.get('test')\nX_tr = train.get('data')[:]\ny_tr = train.get('target')[:]\nX_te = test.get('data')[:]\ny_te = test.get('target')[:]\nf.close()\nusps = np.concatenate((X_tr, X_te)).astype(np.float32)\nlabel = np.concatenate((y_tr, y_te)).astype(np.int32)",
        "detail": "calcu_graph",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 5,
        "importPath": "calcu_graph",
        "description": "calcu_graph",
        "peekOfCode": "train = f.get('train')\ntest = f.get('test')\nX_tr = train.get('data')[:]\ny_tr = train.get('target')[:]\nX_te = test.get('data')[:]\ny_te = test.get('target')[:]\nf.close()\nusps = np.concatenate((X_tr, X_te)).astype(np.float32)\nlabel = np.concatenate((y_tr, y_te)).astype(np.int32)\n'''",
        "detail": "calcu_graph",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 5,
        "importPath": "calcu_graph",
        "description": "calcu_graph",
        "peekOfCode": "test = f.get('test')\nX_tr = train.get('data')[:]\ny_tr = train.get('target')[:]\nX_te = test.get('data')[:]\ny_te = test.get('target')[:]\nf.close()\nusps = np.concatenate((X_tr, X_te)).astype(np.float32)\nlabel = np.concatenate((y_tr, y_te)).astype(np.int32)\n'''\n'''",
        "detail": "calcu_graph",
        "documentation": {}
    },
    {
        "label": "X_tr",
        "kind": 5,
        "importPath": "calcu_graph",
        "description": "calcu_graph",
        "peekOfCode": "X_tr = train.get('data')[:]\ny_tr = train.get('target')[:]\nX_te = test.get('data')[:]\ny_te = test.get('target')[:]\nf.close()\nusps = np.concatenate((X_tr, X_te)).astype(np.float32)\nlabel = np.concatenate((y_tr, y_te)).astype(np.int32)\n'''\n'''\nhhar = np.loadtxt('data/hhar.txt', dtype=float)",
        "detail": "calcu_graph",
        "documentation": {}
    },
    {
        "label": "y_tr",
        "kind": 5,
        "importPath": "calcu_graph",
        "description": "calcu_graph",
        "peekOfCode": "y_tr = train.get('target')[:]\nX_te = test.get('data')[:]\ny_te = test.get('target')[:]\nf.close()\nusps = np.concatenate((X_tr, X_te)).astype(np.float32)\nlabel = np.concatenate((y_tr, y_te)).astype(np.int32)\n'''\n'''\nhhar = np.loadtxt('data/hhar.txt', dtype=float)\nlabel = np.loadtxt('data/hhar_label.txt', dtype=int)",
        "detail": "calcu_graph",
        "documentation": {}
    },
    {
        "label": "X_te",
        "kind": 5,
        "importPath": "calcu_graph",
        "description": "calcu_graph",
        "peekOfCode": "X_te = test.get('data')[:]\ny_te = test.get('target')[:]\nf.close()\nusps = np.concatenate((X_tr, X_te)).astype(np.float32)\nlabel = np.concatenate((y_tr, y_te)).astype(np.int32)\n'''\n'''\nhhar = np.loadtxt('data/hhar.txt', dtype=float)\nlabel = np.loadtxt('data/hhar_label.txt', dtype=int)\n'''",
        "detail": "calcu_graph",
        "documentation": {}
    },
    {
        "label": "y_te",
        "kind": 5,
        "importPath": "calcu_graph",
        "description": "calcu_graph",
        "peekOfCode": "y_te = test.get('target')[:]\nf.close()\nusps = np.concatenate((X_tr, X_te)).astype(np.float32)\nlabel = np.concatenate((y_tr, y_te)).astype(np.int32)\n'''\n'''\nhhar = np.loadtxt('data/hhar.txt', dtype=float)\nlabel = np.loadtxt('data/hhar_label.txt', dtype=int)\n'''\nreut = np.loadtxt('data/reut.txt', dtype=float)",
        "detail": "calcu_graph",
        "documentation": {}
    },
    {
        "label": "usps",
        "kind": 5,
        "importPath": "calcu_graph",
        "description": "calcu_graph",
        "peekOfCode": "usps = np.concatenate((X_tr, X_te)).astype(np.float32)\nlabel = np.concatenate((y_tr, y_te)).astype(np.int32)\n'''\n'''\nhhar = np.loadtxt('data/hhar.txt', dtype=float)\nlabel = np.loadtxt('data/hhar_label.txt', dtype=int)\n'''\nreut = np.loadtxt('data/reut.txt', dtype=float)\nlabel = np.loadtxt('data/reut_label.txt', dtype=int)\nconstruct_graph(reut, label, 'ncos')",
        "detail": "calcu_graph",
        "documentation": {}
    },
    {
        "label": "label",
        "kind": 5,
        "importPath": "calcu_graph",
        "description": "calcu_graph",
        "peekOfCode": "label = np.concatenate((y_tr, y_te)).astype(np.int32)\n'''\n'''\nhhar = np.loadtxt('data/hhar.txt', dtype=float)\nlabel = np.loadtxt('data/hhar_label.txt', dtype=int)\n'''\nreut = np.loadtxt('data/reut.txt', dtype=float)\nlabel = np.loadtxt('data/reut_label.txt', dtype=int)\nconstruct_graph(reut, label, 'ncos')",
        "detail": "calcu_graph",
        "documentation": {}
    },
    {
        "label": "hhar",
        "kind": 5,
        "importPath": "calcu_graph",
        "description": "calcu_graph",
        "peekOfCode": "hhar = np.loadtxt('data/hhar.txt', dtype=float)\nlabel = np.loadtxt('data/hhar_label.txt', dtype=int)\n'''\nreut = np.loadtxt('data/reut.txt', dtype=float)\nlabel = np.loadtxt('data/reut_label.txt', dtype=int)\nconstruct_graph(reut, label, 'ncos')",
        "detail": "calcu_graph",
        "documentation": {}
    },
    {
        "label": "label",
        "kind": 5,
        "importPath": "calcu_graph",
        "description": "calcu_graph",
        "peekOfCode": "label = np.loadtxt('data/hhar_label.txt', dtype=int)\n'''\nreut = np.loadtxt('data/reut.txt', dtype=float)\nlabel = np.loadtxt('data/reut_label.txt', dtype=int)\nconstruct_graph(reut, label, 'ncos')",
        "detail": "calcu_graph",
        "documentation": {}
    },
    {
        "label": "reut",
        "kind": 5,
        "importPath": "calcu_graph",
        "description": "calcu_graph",
        "peekOfCode": "reut = np.loadtxt('data/reut.txt', dtype=float)\nlabel = np.loadtxt('data/reut_label.txt', dtype=int)\nconstruct_graph(reut, label, 'ncos')",
        "detail": "calcu_graph",
        "documentation": {}
    },
    {
        "label": "label",
        "kind": 5,
        "importPath": "calcu_graph",
        "description": "calcu_graph",
        "peekOfCode": "label = np.loadtxt('data/reut_label.txt', dtype=int)\nconstruct_graph(reut, label, 'ncos')",
        "detail": "calcu_graph",
        "documentation": {}
    },
    {
        "label": "celf",
        "kind": 2,
        "importPath": "celf",
        "description": "celf",
        "peekOfCode": "def celf(g, k, p=0.1, mc=10000, method='random'):\n    # --------------------\n    # 用贪婪算法找到第一个节点\n    # --------------------\n    # 计算第一次迭代排序列表\n    start_time = time.time()\n    # 计算每个节点的扩展度\n    marg_gain = [IC(g, [node], p, mc, method=method) for node in g.nodes()]\n    # sorted(iterable, key, reverse=False)：排序且不改变可迭代对象本身\n    # - iterable: 可迭代对象，如集合、元组、数组",
        "detail": "celf",
        "documentation": {}
    },
    {
        "label": "celf",
        "kind": 2,
        "importPath": "celf_networkx",
        "description": "celf_networkx",
        "peekOfCode": "def celf(g, k, p=0.1, mc=10000):\n    # --------------------\n    # 用贪婪算法找到第一个节点\n    # --------------------\n    # 计算第一次迭代排序列表\n    start_time = time.time()\n    # 计算每个节点的扩展度\n    marg_gain = [IC(g, [node], p, mc) for node in g.nodes()]\n    # sorted(iterable, key, reverse=False)：排序且不改变可迭代对象本身\n    # - iterable: 可迭代对象，如集合、元组、数组",
        "detail": "celf_networkx",
        "documentation": {}
    },
    {
        "label": "get_comm",
        "kind": 2,
        "importPath": "community",
        "description": "community",
        "peekOfCode": "def get_comm(name):\n    f1 = open('data/' + name + '_result_Z.txt', 'r', encoding='utf-8')\n    data = f1.read().replace('\\n', '')[1:-1].split(' ')\n    comm1 = []\n    comm2 = []\n    comm3 = []\n    comm4 = []\n    for i, d in enumerate(data):\n        d = int(d)\n        if d == 0:",
        "detail": "community",
        "documentation": {}
    },
    {
        "label": "get_graph",
        "kind": 2,
        "importPath": "community",
        "description": "community",
        "peekOfCode": "def get_graph(comm):\n    f = open('graph/dblp_graph.txt', 'r', encoding='utf-8')\n    source = []\n    target = []\n    vertices = set()\n    for line in f.readlines():\n        n1 = int(line.split(' ')[0])\n        n2 = int(line.split(' ')[1].replace('\\n', ''))\n        if (n1 in comm) and (n2 in comm):\n            vertices.add(n1)",
        "detail": "community",
        "documentation": {}
    },
    {
        "label": "get_comm",
        "kind": 2,
        "importPath": "community_p",
        "description": "community_p",
        "peekOfCode": "def get_comm(name):\n    f1 = open('data/' + name + '_result_Z.txt', 'r', encoding='utf-8')\n    data = f1.read().replace('\\n', '')[1:-1].split(' ')\n    comm1 = []\n    comm2 = []\n    comm3 = []\n    comm4 = []\n    for i, d in enumerate(data):\n        d = int(d)\n        if d == 0:",
        "detail": "community_p",
        "documentation": {}
    },
    {
        "label": "get_graph",
        "kind": 2,
        "importPath": "community_p",
        "description": "community_p",
        "peekOfCode": "def get_graph(comm):\n    f = open('result/dblp/dblp_cosine.txt', 'r', encoding='utf-8')\n    g = nx.DiGraph()\n    for line in f.readlines():\n        n1 = int(line.split(' ')[0])\n        n2 = int(line.split(' ')[1])\n        weight = line.split(' ')[2].replace('\\n', '')\n        if (n1 in comm) and (n2 in comm):\n            g.add_node(n1)\n            g.add_node(n2)",
        "detail": "community_p",
        "documentation": {}
    },
    {
        "label": "cluster_acc",
        "kind": 2,
        "importPath": "evaluation",
        "description": "evaluation",
        "peekOfCode": "def cluster_acc(y_true, y_pred):\n    y_true = y_true - np.min(y_true)\n    l1 = list(set(y_true))\n    numclass1 = len(l1)\n    l2 = list(set(y_pred))\n    numclass2 = len(l2)\n    ind = 0\n    if numclass1 != numclass2:\n        for i in l1:\n            if i in l2:",
        "detail": "evaluation",
        "documentation": {}
    },
    {
        "label": "eva",
        "kind": 2,
        "importPath": "evaluation",
        "description": "evaluation",
        "peekOfCode": "def eva(y_true, y_pred, epoch=0):\n    acc, f1 = cluster_acc(y_true, y_pred)\n    nmi = nmi_score(y_true, y_pred, average_method='arithmetic')\n    ari = ari_score(y_true, y_pred)\n    print(epoch, ':acc {:.4f}'.format(acc), ', nmi {:.4f}'.format(nmi), ', ari {:.4f}'.format(ari),\n            ', f1 {:.4f}'.format(f1))\n    f = open('data/eva_result.txt', 'a', encoding='utf-8')\n    f.write(epoch + ':\\n' + 'acc: {:.4f}'.format(acc) + ', nmi: {:.4f}'.format(nmi) + ', ari: {:.4f}'.format(ari) + ', f1: {:.4f}'.format(f1) + '\\n')\n    f.close()",
        "detail": "evaluation",
        "documentation": {}
    },
    {
        "label": "getP",
        "kind": 2,
        "importPath": "getP",
        "description": "getP",
        "peekOfCode": "def getP(name, p):\n    f1 = open('graph/' + name + '_graph.txt', 'r', encoding='utf-8')\n    f2 = open('result/' + name + '/' + name + '_graph.txt', 'w', encoding='utf-8')\n    for line in f1.readlines():\n        f2.write(line.replace('\\n', '') + ' ' + str(p) + '\\n')\n    f1.close()\n    f2.close()\nif __name__ == '__main__':\n    getP('dblp', 0.1)",
        "detail": "getP",
        "documentation": {}
    },
    {
        "label": "greedy",
        "kind": 2,
        "importPath": "greedy_networkx",
        "description": "greedy_networkx",
        "peekOfCode": "def greedy(g, k, p=0.1, mc=1000):\n    S, spread, timelapse, start_time = [], [], [], time.time()\n    # 寻找具有最大边际增益的k个节点\n    for _ in range(k):\n        best_spread = 0\n        # 遍历不在种子集中的节点，找到有最大边际效益的节点\n        for j in set(g.nodes()) - set(S):\n            # 计算扩展度\n            s = IC(g, S+[j], p, mc)\n            if s > best_spread:",
        "detail": "greedy_networkx",
        "documentation": {}
    },
    {
        "label": "load_data",
        "kind": 2,
        "importPath": "mpTest",
        "description": "mpTest",
        "peekOfCode": "def load_data(data, n_clusters):\n    communities = []\n    select_num = []\n    for i in range(n_clusters):\n        communities.append([])\n    # 获得社区\n    for i, d in enumerate(data):\n        communities[d].append(i)\n    select_num = [len(communities[i]) for i in range(n_clusters)]\n    for i in range(n_clusters):",
        "detail": "mpTest",
        "documentation": {}
    },
    {
        "label": "commCelf",
        "kind": 2,
        "importPath": "mpTest",
        "description": "mpTest",
        "peekOfCode": "def commCelf(q, l, i, comm, k):\n    l.acquire()\n    print('Run comm %s ...' % (i))\n    G = nx.Graph()\n    G.add_nodes_from([int(x) for x in comm])\n    f = open('graph/dblp_graph.txt', 'r', encoding='utf-8')\n    for line in f.readlines():\n        n1 = int(line.strip().split()[0])\n        n2 = int(line.strip().split()[1])\n        if (n1 in comm) and (n2 in comm):",
        "detail": "mpTest",
        "documentation": {}
    },
    {
        "label": "mpCommCelf",
        "kind": 2,
        "importPath": "mpTest",
        "description": "mpTest",
        "peekOfCode": "def mpCommCelf(data, n_clusters):\n    communities, select_num = load_data(data, n_clusters)\n    seeds_list = []\n    q = Queue()\n    lock = Lock()\n    for i in range(n_clusters):\n        comm = communities[i]\n        k = select_num[i]\n        p = Process(target=comm_celf, args=(q, lock, i, comm, k))\n        p.start()",
        "detail": "mpTest",
        "documentation": {}
    },
    {
        "label": "commAI",
        "kind": 2,
        "importPath": "mpTest",
        "description": "mpTest",
        "peekOfCode": "def commAI(q, l, i, comm, k):\n    l.acquire()\n    print('Run comm %s ...' % (i))\n    G = nx.Graph()\n    G.add_nodes_from([int(x) for x in comm])\n    f = open('graph/dblp_graph.txt', 'r', encoding='utf-8')\n    for line in f.readlines():\n        n1 = int(line.strip().split()[0])\n        n2 = int(line.strip().split()[1])\n        if (n1 in comm) and (n2 in comm):",
        "detail": "mpTest",
        "documentation": {}
    },
    {
        "label": "mpCommAI",
        "kind": 2,
        "importPath": "mpTest",
        "description": "mpTest",
        "peekOfCode": "def mpCommAI(data, n_clusters):\n    communities, select_num = load_data(data, n_clusters)\n    seeds_list = []\n    q = Queue()\n    lock = Lock()\n    for i in range(n_clusters):\n        comm = communities[i]\n        k = select_num[i]\n        p = Process(target=commAI, args=(q, lock, i, comm, k))\n        p.start()",
        "detail": "mpTest",
        "documentation": {}
    },
    {
        "label": "pGraph",
        "kind": 6,
        "importPath": "pGraph",
        "description": "pGraph",
        "peekOfCode": "class pGraph():\n    \"\"\"\n        graph data structure to store the network\n    :return:\n    \"\"\"\n    def __init__(self):\n        self.network = dict()\n    def add_node(self, node):\n        if node not in self.network:\n            self.network[node] = dict()",
        "detail": "pGraph",
        "documentation": {}
    },
    {
        "label": "AE",
        "kind": 6,
        "importPath": "sdcn",
        "description": "sdcn",
        "peekOfCode": "class AE(nn.Module):\n    def __init__(self, n_enc_1, n_enc_2, n_enc_3, n_dec_1, n_dec_2, n_dec_3,\n                 n_input, n_z):\n        super(AE, self).__init__()\n        self.enc_1 = Linear(n_input, n_enc_1)\n        self.enc_2 = Linear(n_enc_1, n_enc_2)\n        self.enc_3 = Linear(n_enc_2, n_enc_3)\n        self.z_layer = Linear(n_enc_3, n_z)\n        self.dec_1 = Linear(n_z, n_dec_1)\n        self.dec_2 = Linear(n_dec_1, n_dec_2)",
        "detail": "sdcn",
        "documentation": {}
    },
    {
        "label": "SDCN",
        "kind": 6,
        "importPath": "sdcn",
        "description": "sdcn",
        "peekOfCode": "class SDCN(nn.Module):\n    def __init__(self, n_enc_1, n_enc_2, n_enc_3, n_dec_1, n_dec_2, n_dec_3, \n                n_input, n_z, n_clusters, v=1):\n        super(SDCN, self).__init__()\n        # autoencoder for intra information\n        self.ae = AE(\n            n_enc_1=n_enc_1,\n            n_enc_2=n_enc_2,\n            n_enc_3=n_enc_3,\n            n_dec_1=n_dec_1,",
        "detail": "sdcn",
        "documentation": {}
    },
    {
        "label": "target_distribution",
        "kind": 2,
        "importPath": "sdcn",
        "description": "sdcn",
        "peekOfCode": "def target_distribution(q):\n    weight = q**2 / q.sum(0)\n    return (weight.t() / weight.sum(1)).t()\n# 在每一个社区内选点\ndef selectInComm(comm, k):\n    G = nx.Graph()\n    G.add_nodes_from([int(x) for x in comm])\n    f = open('graph/dblp_graph.txt', 'r', encoding='utf-8')\n    for line in f.readlines():\n        n1 = int(line.strip().split()[0])",
        "detail": "sdcn",
        "documentation": {}
    },
    {
        "label": "selectInComm",
        "kind": 2,
        "importPath": "sdcn",
        "description": "sdcn",
        "peekOfCode": "def selectInComm(comm, k):\n    G = nx.Graph()\n    G.add_nodes_from([int(x) for x in comm])\n    f = open('graph/dblp_graph.txt', 'r', encoding='utf-8')\n    for line in f.readlines():\n        n1 = int(line.strip().split()[0])\n        n2 = int(line.strip().split()[1])\n        if (n1 in comm) and (n2 in comm):\n            G.add_edge(n1, n2)\n    seeds, spread, timelapse, lookup = celf(G, k, p=0.1, mc=10000, method='random')",
        "detail": "sdcn",
        "documentation": {}
    },
    {
        "label": "train_sdcn",
        "kind": 2,
        "importPath": "sdcn",
        "description": "sdcn",
        "peekOfCode": "def train_sdcn(dataset):\n    res_file = open('commResult/1.txt', 'w', encoding='utf-8')\n    res_file.write('数目与社区大小成正比，使用celf在社区内选点，社区串行\\n')\n    res_file.write('loss: 20 * 1/spreadSum\\n')\n    model = SDCN(500, 500, 2000, 2000, 500, 500,\n                n_input=args.n_input,\n                n_z=args.n_z,\n                n_clusters=args.n_clusters,\n                v=1.0).to(device)\n    print(model)",
        "detail": "sdcn",
        "documentation": {}
    },
    {
        "label": "AE",
        "kind": 6,
        "importPath": "sdcn1",
        "description": "sdcn1",
        "peekOfCode": "class AE(nn.Module):\n    def __init__(self, n_enc_1, n_enc_2, n_enc_3, n_dec_1, n_dec_2, n_dec_3,\n                 n_input, n_z):\n        super(AE, self).__init__()\n        self.enc_1 = Linear(n_input, n_enc_1)\n        self.enc_2 = Linear(n_enc_1, n_enc_2)\n        self.enc_3 = Linear(n_enc_2, n_enc_3)\n        self.z_layer = Linear(n_enc_3, n_z)\n        self.dec_1 = Linear(n_z, n_dec_1)\n        self.dec_2 = Linear(n_dec_1, n_dec_2)",
        "detail": "sdcn1",
        "documentation": {}
    },
    {
        "label": "SDCN",
        "kind": 6,
        "importPath": "sdcn1",
        "description": "sdcn1",
        "peekOfCode": "class SDCN(nn.Module):\n    def __init__(self, n_enc_1, n_enc_2, n_enc_3, n_dec_1, n_dec_2, n_dec_3, \n                n_input, n_z, n_clusters, v=1):\n        super(SDCN, self).__init__()\n        # autoencoder for intra information\n        self.ae = AE(\n            n_enc_1=n_enc_1,\n            n_enc_2=n_enc_2,\n            n_enc_3=n_enc_3,\n            n_dec_1=n_dec_1,",
        "detail": "sdcn1",
        "documentation": {}
    },
    {
        "label": "target_distribution",
        "kind": 2,
        "importPath": "sdcn1",
        "description": "sdcn1",
        "peekOfCode": "def target_distribution(q):\n    weight = q**2 / q.sum(0)\n    return (weight.t() / weight.sum(1)).t()\ndef train_sdcn(dataset):\n    res_file = open('commResult/2.txt', 'w', encoding='utf-8')\n    res_file.write('数目与社区大小成正比，使用celf在社区内选点，社区并行\\n')\n    res_file.write('loss: 20 * 1/spreadSum\\n')\n    start = time.time()\n    model = SDCN(500, 500, 2000, 2000, 500, 500,\n                n_input=args.n_input,",
        "detail": "sdcn1",
        "documentation": {}
    },
    {
        "label": "train_sdcn",
        "kind": 2,
        "importPath": "sdcn1",
        "description": "sdcn1",
        "peekOfCode": "def train_sdcn(dataset):\n    res_file = open('commResult/2.txt', 'w', encoding='utf-8')\n    res_file.write('数目与社区大小成正比，使用celf在社区内选点，社区并行\\n')\n    res_file.write('loss: 20 * 1/spreadSum\\n')\n    start = time.time()\n    model = SDCN(500, 500, 2000, 2000, 500, 500,\n                n_input=args.n_input,\n                n_z=args.n_z,\n                n_clusters=args.n_clusters,\n                v=1.0).to(device)",
        "detail": "sdcn1",
        "documentation": {}
    },
    {
        "label": "AE",
        "kind": 6,
        "importPath": "sdcn2",
        "description": "sdcn2",
        "peekOfCode": "class AE(nn.Module):\n    def __init__(self, n_enc_1, n_enc_2, n_enc_3, n_dec_1, n_dec_2, n_dec_3,\n                 n_input, n_z):\n        super(AE, self).__init__()\n        self.enc_1 = Linear(n_input, n_enc_1)\n        self.enc_2 = Linear(n_enc_1, n_enc_2)\n        self.enc_3 = Linear(n_enc_2, n_enc_3)\n        self.z_layer = Linear(n_enc_3, n_z)\n        self.dec_1 = Linear(n_z, n_dec_1)\n        self.dec_2 = Linear(n_dec_1, n_dec_2)",
        "detail": "sdcn2",
        "documentation": {}
    },
    {
        "label": "SDCN",
        "kind": 6,
        "importPath": "sdcn2",
        "description": "sdcn2",
        "peekOfCode": "class SDCN(nn.Module):\n    def __init__(self, n_enc_1, n_enc_2, n_enc_3, n_dec_1, n_dec_2, n_dec_3, \n                n_input, n_z, n_clusters, v=1):\n        super(SDCN, self).__init__()\n        # autoencoder for intra information\n        self.ae = AE(\n            n_enc_1=n_enc_1,\n            n_enc_2=n_enc_2,\n            n_enc_3=n_enc_3,\n            n_dec_1=n_dec_1,",
        "detail": "sdcn2",
        "documentation": {}
    },
    {
        "label": "target_distribution",
        "kind": 2,
        "importPath": "sdcn2",
        "description": "sdcn2",
        "peekOfCode": "def target_distribution(q):\n    weight = q**2 / q.sum(0)\n    return (weight.t() / weight.sum(1)).t()\ndef train_sdcn(dataset):\n    res_file = open('commResult/3.txt', 'w', encoding='utf-8')\n    res_file.write('数目与社区大小成正比，使用AI在社区内选点，社区并行\\n')\n    res_file.write('loss: 20 * 1/spreadSum\\n')\n    start = time.time()\n    model = SDCN(500, 500, 2000, 2000, 500, 500,\n                n_input=args.n_input,",
        "detail": "sdcn2",
        "documentation": {}
    },
    {
        "label": "train_sdcn",
        "kind": 2,
        "importPath": "sdcn2",
        "description": "sdcn2",
        "peekOfCode": "def train_sdcn(dataset):\n    res_file = open('commResult/3.txt', 'w', encoding='utf-8')\n    res_file.write('数目与社区大小成正比，使用AI在社区内选点，社区并行\\n')\n    res_file.write('loss: 20 * 1/spreadSum\\n')\n    start = time.time()\n    model = SDCN(500, 500, 2000, 2000, 500, 500,\n                n_input=args.n_input,\n                n_z=args.n_z,\n                n_clusters=args.n_clusters,\n                v=1.0).to(device)",
        "detail": "sdcn2",
        "documentation": {}
    },
    {
        "label": "comm",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "comm = [2, 3, 7, 8, 1, 10, 4]\nG = nx.Graph()\nG.add_nodes_from([int(x) for x in comm])\nG.add_edge(2, 3, weight=0.1)\nG.add_edge(1, 2, weight=0.1)\nG.add_edge(4, 7, weight=0.1)\nG.add_edge(8, 10, weight=0.1)\nnum = G.number_of_nodes()\nI = np.ones((num, 1))\nA = nx.to_numpy_matrix(G)",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "G",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "G = nx.Graph()\nG.add_nodes_from([int(x) for x in comm])\nG.add_edge(2, 3, weight=0.1)\nG.add_edge(1, 2, weight=0.1)\nG.add_edge(4, 7, weight=0.1)\nG.add_edge(8, 10, weight=0.1)\nnum = G.number_of_nodes()\nI = np.ones((num, 1))\nA = nx.to_numpy_matrix(G)\nsigma = I",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "num",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "num = G.number_of_nodes()\nI = np.ones((num, 1))\nA = nx.to_numpy_matrix(G)\nsigma = I\nfor i in range(10):\n    B = np.power(A, i+1)\n    C = np.matmul(B, I)\n    sigma += C\nvalue = {}\nfor i in range(num):",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "I",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "I = np.ones((num, 1))\nA = nx.to_numpy_matrix(G)\nsigma = I\nfor i in range(10):\n    B = np.power(A, i+1)\n    C = np.matmul(B, I)\n    sigma += C\nvalue = {}\nfor i in range(num):\n    value[comm[i]] = sigma[i, 0]",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "A",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "A = nx.to_numpy_matrix(G)\nsigma = I\nfor i in range(10):\n    B = np.power(A, i+1)\n    C = np.matmul(B, I)\n    sigma += C\nvalue = {}\nfor i in range(num):\n    value[comm[i]] = sigma[i, 0]\n# 从大到小排序",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "sigma",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "sigma = I\nfor i in range(10):\n    B = np.power(A, i+1)\n    C = np.matmul(B, I)\n    sigma += C\nvalue = {}\nfor i in range(num):\n    value[comm[i]] = sigma[i, 0]\n# 从大到小排序\nvalue_sorted = sorted(value.items(), key=lambda item: item[1], reverse=True)",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "value",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "value = {}\nfor i in range(num):\n    value[comm[i]] = sigma[i, 0]\n# 从大到小排序\nvalue_sorted = sorted(value.items(), key=lambda item: item[1], reverse=True)\nprint(value_sorted)\nseeds = []\nfor i in range(5):\n    seeds.append(value_sorted[i][0])\nprint(seeds)",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "value_sorted",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "value_sorted = sorted(value.items(), key=lambda item: item[1], reverse=True)\nprint(value_sorted)\nseeds = []\nfor i in range(5):\n    seeds.append(value_sorted[i][0])\nprint(seeds)",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "seeds",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "seeds = []\nfor i in range(5):\n    seeds.append(value_sorted[i][0])\nprint(seeds)",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "load_data",
        "kind": 6,
        "importPath": "utils",
        "description": "utils",
        "peekOfCode": "class load_data(Dataset):\n    def __init__(self, dataset):\n        self.x = np.loadtxt('data/{}.txt'.format(dataset), dtype=float)\n        self.y = np.loadtxt('data/{}_label.txt'.format(dataset), dtype=int)\n    def __len__(self):\n        return self.x.shape[0]\n    def __getitem__(self, idx):\n        return torch.from_numpy(np.array(self.x[idx])),\\\n               torch.from_numpy(np.array(self.y[idx])),\\\n               torch.from_numpy(np.array(idx))",
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "load_graph",
        "kind": 2,
        "importPath": "utils",
        "description": "utils",
        "peekOfCode": "def load_graph(dataset, k):\n    if k:\n        path = 'graph/{}{}_graph.txt'.format(dataset, k) \n    else:\n        path = 'graph/{}_graph.txt'.format(dataset) \n    data = np.loadtxt('data/{}.txt'.format(dataset))\n    n, _ = data.shape\n    idx = np.array([i for i in range(n)], dtype=np.int32)\n    idx_map = {j: i for i, j in enumerate(idx)}\n    edges_unordered = np.genfromtxt(path, dtype=np.int32)",
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "normalize",
        "kind": 2,
        "importPath": "utils",
        "description": "utils",
        "peekOfCode": "def normalize(mx):\n    \"\"\"Row-normalize sparse matrix\"\"\"\n    rowsum = np.array(mx.sum(1))\n    r_inv = np.power(rowsum, -1).flatten()\n    r_inv[np.isinf(r_inv)] = 0.\n    r_mat_inv = sp.diags(r_inv)\n    mx = r_mat_inv.dot(mx)\n    return mx\ndef sparse_mx_to_torch_sparse_tensor(sparse_mx):\n    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"",
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "sparse_mx_to_torch_sparse_tensor",
        "kind": 2,
        "importPath": "utils",
        "description": "utils",
        "peekOfCode": "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n    indices = torch.from_numpy(\n        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n    values = torch.from_numpy(sparse_mx.data)\n    shape = torch.Size(sparse_mx.shape)\n    return torch.sparse.FloatTensor(indices, values, shape)\nclass load_data(Dataset):\n    def __init__(self, dataset):",
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "get_graph",
        "kind": 2,
        "importPath": "utils",
        "description": "utils",
        "peekOfCode": "def get_graph(path):\n    f = open(path, 'r', encoding='utf-8')\n    source = []\n    target = []\n    vertices = set()\n    for line in f.readlines():\n        n1 = int(line.split(' ')[0])\n        n2 = int(line.split(' ')[1].replace('\\n', ''))\n        vertices.add(n1)\n        vertices.add(n2)",
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "get_graph_w",
        "kind": 2,
        "importPath": "utils",
        "description": "utils",
        "peekOfCode": "def get_graph_w(path):\n    f = open(path, 'r', encoding='utf-8')\n    g = nx.DiGraph()\n    for line in f.readlines():\n        source = int(line.split(' ')[0])\n        target = int(line.split(' ')[1])\n        weight = float(line.split(' ')[2].replace('\\n', ''))\n        g.add_node(source)\n        g.add_node(target)\n        g.add_edge(source, target, pp=weight)",
        "detail": "utils",
        "documentation": {}
    }
]